{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f4826bc-f209-4d6e-acff-947c9090c15c",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4341aa4e-a239-49b9-9c91-513f061318ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\"\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff136047-5b29-45db-921a-5a29672268ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torchvision.transforms.v2 as transforms\n",
    "from IPython.display import clear_output\n",
    "from monai.networks.nets import resnet10\n",
    "from skimage.io import imread, imsave\n",
    "from torch import nn\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import transforms3d as T\n",
    "from dataset3d import BNSet, BNSetMasks, get_dloader_mask, get_dloader_noise\n",
    "from model3d import CNN3d\n",
    "from util3d import get_obj_score3d, get_saliency3d, show_volume\n",
    "\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2372aa80-4046-48a0-8b68-1ccf47e1baa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = \"../data/bugNIST_DATA\"\n",
    "data_dir = \"/work3/s191510/data/BugNIST_DATA\"\n",
    "\n",
    "name_legend = {\n",
    "    \"ac\": \"brown_cricket\",\n",
    "    \"bc\": \"black_cricket\",\n",
    "    \"bf\": \"blow_fly\",\n",
    "    \"bl\": \"buffalo_bettle_larva\",\n",
    "    \"bp\": \"blow_fly_pupa\",\n",
    "    \"cf\": \"curly-wing_fly\",\n",
    "    \"gh\": \"grasshopper\",\n",
    "    \"ma\": \"maggot\",\n",
    "    \"ml\": \"mealworm\",\n",
    "    \"pp\": \"green_bottle_fly_pupa\",\n",
    "    \"sl\": \"soldier_fly_larva\",\n",
    "    \"wo\": \"woodlice\",\n",
    "}\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44170487-559b-4764-a5e3-6e48829a67ee",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "290e8b02-17ca-49c7-ba80-62f08889c0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "\n",
    "batch_size = 16\n",
    "num_workers = 16\n",
    "\n",
    "# subset = [\"bc\", \"wo\"]\n",
    "# subset = [\"ac\", \"bc\", \"ml\"]\n",
    "subset = list(name_legend.keys())\n",
    "\n",
    "persistent_workers = num_workers > 0\n",
    "trainloader = get_dloader_noise(\n",
    "    \"train\",\n",
    "    batch_size,\n",
    "    data_dir=data_dir,\n",
    "    subset=subset,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=persistent_workers,\n",
    ")\n",
    "valloader = get_dloader_noise(\n",
    "    \"val\",\n",
    "    batch_size=1,\n",
    "    data_dir=data_dir,\n",
    "    subset=subset,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    "    persistent_workers=persistent_workers,\n",
    ")\n",
    "\n",
    "# model = CNN3d(len(name_legend))\n",
    "# model = resnet18(\n",
    "#     spatial_dims=3,\n",
    "#     n_input_channels=1,\n",
    "#     num_classes=len(name_legend),\n",
    "# )\n",
    "model = resnet10(\n",
    "    spatial_dims=3,\n",
    "    n_input_channels=1,\n",
    "    no_max_pool=False,\n",
    "    conv1_t_stride=2,\n",
    "    num_classes=len(name_legend),\n",
    ")\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "get_input = lambda volumes, masks, noise: volumes * masks + ~masks * noise\n",
    "# get_input = lambda volumes, masks, noise: volumes * masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ebf696c9-dc3c-4d12-a530-232c0cc93901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b58357fa8b2463daa9b362d827a5c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/344 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "000684773c154e7bbb7ae56a8149c455",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1831 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "IndexError",
     "evalue": "Caught IndexError in DataLoader worker process 10.\nOriginal Traceback (most recent call last):\n  File \"/zhome/28/4/143111/context/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/zhome/28/4/143111/context/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/zhome/28/4/143111/context/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/zhome/28/4/143111/gitrepos/cnn-context/notebooks/../dataset3d.py\", line 157, in __getitem__\n    noise = self.noise_sampler(item).copy()[np.newaxis]\n  File \"/zhome/28/4/143111/gitrepos/cnn-context/notebooks/../dataset3d.py\", line 148, in sampler\n    return self.noise[item % len(self)]\n  File \"/zhome/28/4/143111/context/lib/python3.10/site-packages/numpy/core/memmap.py\", line 335, in __getitem__\n    res = super().__getitem__(index)\nIndexError: index 1098 is out of bounds for axis 0 with size 1098\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m\n\u001b[1;32m     31\u001b[0m     metrics_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(labels\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     33\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m volumes, labels, masks, noise \u001b[38;5;129;01min\u001b[39;00m tqdm(valloader):\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;66;03m# out = model(get_input(volumes, masks, noise).to(device))\u001b[39;00m\n\u001b[1;32m     37\u001b[0m     slc, score, indices, out \u001b[38;5;241m=\u001b[39m get_saliency3d(model, get_input(volumes, masks, noise), device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m     38\u001b[0m     obj_score \u001b[38;5;241m=\u001b[39m get_obj_score3d(slc, masks)\n",
      "File \u001b[0;32m~/context/lib/python3.10/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m~/context/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/context/lib/python3.10/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/context/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/context/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/context/lib/python3.10/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mIndexError\u001b[0m: Caught IndexError in DataLoader worker process 10.\nOriginal Traceback (most recent call last):\n  File \"/zhome/28/4/143111/context/lib/python3.10/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n  File \"/zhome/28/4/143111/context/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in fetch\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/zhome/28/4/143111/context/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py\", line 51, in <listcomp>\n    data = [self.dataset[idx] for idx in possibly_batched_index]\n  File \"/zhome/28/4/143111/gitrepos/cnn-context/notebooks/../dataset3d.py\", line 157, in __getitem__\n    noise = self.noise_sampler(item).copy()[np.newaxis]\n  File \"/zhome/28/4/143111/gitrepos/cnn-context/notebooks/../dataset3d.py\", line 148, in sampler\n    return self.noise[item % len(self)]\n  File \"/zhome/28/4/143111/context/lib/python3.10/site-packages/numpy/core/memmap.py\", line 335, in __getitem__\n    res = super().__getitem__(index)\nIndexError: index 1098 is out of bounds for axis 0 with size 1098\n"
     ]
    }
   ],
   "source": [
    "stats = {}\n",
    "for epoch in range(0, 50):\n",
    "    metrics_train = {\n",
    "        \"loss\": [],\n",
    "        \"preds\": [],\n",
    "        \"labels\": [],\n",
    "    }\n",
    "    metrics_val = {\n",
    "        \"loss\": [],\n",
    "        \"preds\": [],\n",
    "        \"labels\": [],\n",
    "        \"object_scores\": [],\n",
    "    }\n",
    "\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    model.train()\n",
    "    for volumes, labels, masks, noise in tqdm(trainloader):\n",
    "        out = model(get_input(volumes, masks, noise).to(device))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(out, labels.type(torch.LongTensor).to(device))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "        _, indices = torch.max(out.cpu(), 1)\n",
    "\n",
    "        metrics_train[\"loss\"].append(loss.cpu().detach().item())\n",
    "        metrics_train[\"preds\"].append(indices.detach().numpy())\n",
    "        metrics_train[\"labels\"].append(labels.numpy())\n",
    "\n",
    "    model.eval()\n",
    "    for volumes, labels, masks, noise in tqdm(valloader):\n",
    "        # out = model(get_input(volumes, masks, noise).to(device))\n",
    "        \n",
    "        slc, score, indices, out = get_saliency3d(model, get_input(volumes, masks, noise), device=device)\n",
    "        obj_score = get_obj_score3d(slc, masks)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            loss = criterion(out.to(device), labels.type(torch.LongTensor).to(device))\n",
    "\n",
    "        _, indices = torch.max(out.cpu(), 1)\n",
    "\n",
    "        metrics_val[\"loss\"].append(loss.cpu().detach().item())\n",
    "        metrics_val[\"preds\"].append(indices.detach().numpy())\n",
    "        metrics_val[\"labels\"].append(labels.numpy())\n",
    "        metrics_val[\"object_scores\"].append(obj_score)\n",
    "\n",
    "    performance = {\n",
    "        \"train_loss\": np.mean(metrics_train[\"loss\"]),\n",
    "        \"train_accuracy\": np.mean(\n",
    "            np.concatenate(metrics_train[\"preds\"])\n",
    "            == np.concatenate(metrics_train[\"labels\"])\n",
    "        ).item(),\n",
    "        \"val_loss\": np.mean(metrics_val[\"loss\"]),\n",
    "        \"val_accuracy\": np.mean(\n",
    "            np.concatenate(metrics_val[\"preds\"])\n",
    "            == np.concatenate(metrics_val[\"labels\"])\n",
    "        ).item(),\n",
    "        \"obj_score\": np.mean(metrics_val[\"object_scores\"]),\n",
    "    }\n",
    "    print(performance)\n",
    "    stats[epoch] = performance\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8366fa2-dfc1-4f28-a65f-46c2d37d747c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "fig, (ax0, ax1, ax2) = plt.subplots(1, 3, figsize=(15, 3), dpi=150)\n",
    "\n",
    "ax0.plot(stats.keys(), [stats[epoch][\"train_loss\"] for epoch in stats])\n",
    "ax0.plot(stats.keys(), [stats[epoch][\"val_loss\"] for epoch in stats])\n",
    "ax0.set_title(\"CE Loss\")\n",
    "\n",
    "ax1.plot(stats.keys(), [stats[epoch][\"train_accuracy\"] * 100 for epoch in stats])\n",
    "ax1.plot(stats.keys(), [stats[epoch][\"val_accuracy\"] * 100 for epoch in stats])\n",
    "ax1.set_title(\"Accuracy\")\n",
    "\n",
    "ax2.plot(stats.keys(), [stats[epoch][\"obj_score\"] * 100 for epoch in stats])\n",
    "ax2.set_title(\"Object score\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3ef34a-e23a-4a3c-8e33-aaa3a3468d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = get_dloader_noise(\"val\", 1, data_dir=data_dir, subset=subset, num_workers=0)\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3b02e2-520e-426c-a7b8-be8187674a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader_iter = iter(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23468d7-3f1c-40e1-a744-93841286d57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "volumes, labels, masks, noise = next(dloader_iter)\n",
    "volumes = get_input(volumes, masks, noise)\n",
    "\n",
    "slc, score, indices, out = get_saliency3d(model, volumes, device=device)\n",
    "obj_score = get_obj_score3d(slc, masks)\n",
    "\n",
    "slc_abs = np.abs(slc)\n",
    "\n",
    "size = 3\n",
    "\n",
    "fig, axs = plt.subplots(2, 3, figsize=(size * 3, size * 2), tight_layout=True)\n",
    "\n",
    "label = labels.item()\n",
    "gt = list(name_legend.values())[label].replace(\"_\", \" \")\n",
    "pred = list(name_legend.values())[indices.item()].replace(\"_\", \" \")\n",
    "conf = torch.softmax(out, 1)[0, indices]\n",
    "\n",
    "show_volume(volumes.detach().numpy(), title=f'Ground truth: {gt}\\nPrediction: {pred} ({conf.item():.1%})\\nObj. score: {obj_score:.2f}', cmap=\"viridis\", fig_axs=(fig, axs[0]))\n",
    "show_volume(slc_abs / slc_abs.max(), fig_axs=(fig, axs[1]),  cmap=\"inferno\")\n",
    "plt.show()\n",
    "# obj_score, indices.item(), labels.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e13f526-29ef-43a3-bd4e-41502966a2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj_scores = []\n",
    "for volumes, labels, masks, noise in tqdm(dloader):\n",
    "    volumes = get_input(volumes, masks, noise)\n",
    "\n",
    "    slc, score, indices, out = get_saliency3d(model, volumes, device=device)\n",
    "    obj_score = get_obj_score3d(slc, masks)\n",
    "\n",
    "    obj_scores.append(obj_score)\n",
    "\n",
    "np.mean(obj_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc346d61-3d52-4ff1-996c-0517d78baf9f",
   "metadata": {},
   "source": [
    "Mealworm vs brown cricket:\n",
    "Mean obj score: 0.831"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
