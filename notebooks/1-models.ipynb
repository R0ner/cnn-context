{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c19e30a4-54f5-4e08-94a3-6f9930597697",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99944cd9-97d6-473b-90e8-1a3f1d4cfef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5bb81-0aef-4d6c-abf1-f7771a3cae45",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data\"\n",
    "val_img_dir = f\"{data_dir}/val_images\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "f\"Using device: {device}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb11390-33b9-4afc-bba8-b01d3456e5ee",
   "metadata": {},
   "source": [
    "# Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "353df4a2-2eac-4072-912f-23e8244a48fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HWSet(Dataset):\n",
    "    \"\"\"Dataset class for the Husky vs. Wolf dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.transform = transform\n",
    "        self.val_img_dir = f\"{self.data_dir}/val_images\"\n",
    "\n",
    "        all_labels = np.loadtxt(\n",
    "            f\"{self.data_dir}/ILSVRC2012_validation_ground_truth.txt\"\n",
    "        ).astype(int)\n",
    "        all_img_files = os.listdir(self.val_img_dir)\n",
    "\n",
    "        self.class_indices = []\n",
    "        for idx, name in ((3, \"siberian husky\"), (205, \"grey wolf\")):\n",
    "            self.class_indices.append(np.where(all_labels == idx)[0])\n",
    "\n",
    "        self.labels = []\n",
    "        for label, indices in enumerate(self.class_indices):\n",
    "            self.labels = self.labels + indices.size * [label]\n",
    "        self.labels = np.array(self.labels)\n",
    "\n",
    "        self.imgs = [\n",
    "            all_img_files[idx] for indices in self.class_indices for idx in indices\n",
    "        ]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.labels.size\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        img = Image.open(f\"{val_img_dir}/{self.imgs[item]}\")\n",
    "\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "\n",
    "        return (img, self.labels[item])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3815600a-da61-4bcf-8323-cb18dd7be9e3",
   "metadata": {},
   "source": [
    "## Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df339cb-4b09-420f-9a3b-10fc8e3764d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256, antialias=True),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n",
    "normalize_inv = transforms.Compose(\n",
    "    [\n",
    "        transforms.Normalize(\n",
    "            mean=(0.0, 0.0, 0.0), std=(1 / 0.229, 1 / 0.224, 1 / 0.225)\n",
    "        ),\n",
    "        transforms.Normalize(mean=(-0.485, -0.456, -0.406), std=(1.0, 1.0, 1.0)),\n",
    "    ]\n",
    ")  # For visualization purposes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0bec43a-5041-4061-934c-9fa0a1ea78ee",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f078c4-24c7-477b-bb5a-0355f4917fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dset = HWSet(data_dir, transform=transform)\n",
    "len(dset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da2b2c6-9054-4dbb-94e2-3d2cb654833b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_legend = (\"Siberian Husky\", \"Grey Wolf\")\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 5), tight_layout=True)\n",
    "items = 7, 57\n",
    "\n",
    "for item, ax in zip(items, axs):\n",
    "    img, label = dset[item]\n",
    "\n",
    "    ax.imshow(np.moveaxis(normalize_inv(img).numpy(), 0, -1))\n",
    "    ax.set_title(f\"{item}: {class_legend[label]}\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "355cbc4e-9368-4bf9-b388-fa84b4df512a",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98a695c-9404-49e9-9b6c-db998d519f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = DataLoader(dset, batch_size=1)\n",
    "img_batch, label_batch = next(iter(dloader))\n",
    "\n",
    "img_batch.size(), label_batch.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f17bfb32-029d-4c36-841a-d78fee9490e9",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f84a5ec9-de85-4e64-a510-cf86b8ed10a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = resnet50(weights='IMAGENET1K_V2')\n",
    "model.to(device);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3702ecf2-c283-4b88-ab53-90cf9bcaa284",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0be4769-9374-4e61-964d-f4f1c4d11920",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label to class map.\n",
    "with open(f\"{data_dir}/imagenet1000_clsidx_to_labels.txt\") as f:\n",
    "    idx2label = eval(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9ec536-96d1-4453-b776-12aeb35b3513",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader_iter = iter(dloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e672a81e-b706-4237-8035-67d45b85da78",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = next(dloader_iter)\n",
    "with torch.no_grad():\n",
    "    out = model(img_batch.to(device))\n",
    "    # print(torch.topk(out.flatten(), 5).indices, label_batch.item())\n",
    "print(\n",
    "    f\"Predicted (Top 5):\\t {[idx2label[idx.cpu().item()].split(', ')[0] for idx in torch.topk(out.flatten(), 5).indices]}\\n\" +\n",
    "    f\"Ground truth:\\t\\t {class_legend[label_batch.item()]}\" \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb3c5232-3ac9-4af7-b7ed-7faa5ddc98ea",
   "metadata": {},
   "source": [
    "# Saliency mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52289791-b5f9-4a66-baa5-b57613fc5669",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/sunnynevarekar/pytorch-saliency-maps/blob/master/Saliency_maps_in_pytorch.ipynb\n",
    "def saliency(input, model, label):\n",
    "    #we don't need gradients w.r.t. weights for a trained model\n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    #set model in eval mode\n",
    "    model.eval()\n",
    "    #transoform input PIL image to torch.Tensor and normalize\n",
    "    # input = transform(img)\n",
    "    # input.unsqueeze_(0)\n",
    "\n",
    "    #we want to calculate gradient of higest score w.r.t. input\n",
    "    #so set requires_grad to True for input \n",
    "    input.requires_grad = True\n",
    "    #forward pass to calculate predictions\n",
    "    preds = model(input)\n",
    "    print(\n",
    "        f\"Predicted (Top 5):\\t {[idx2label[idx.cpu().item()].split(', ')[0] for idx in torch.topk(preds.flatten(), 5).indices]}\\n\" +\n",
    "        f\"Ground truth:\\t\\t {class_legend[label.item()]}\" \n",
    "    )\n",
    "    score, indices = torch.max(preds, 1)\n",
    "    #backward pass to get gradients of score predicted class w.r.t. input image\n",
    "    score.backward()\n",
    "    #get max along channel axis\n",
    "    slc, _ = torch.max(torch.abs(input.grad[0]), dim=0)\n",
    "    #normalize to [0..1]\n",
    "    slc = (slc - slc.min())/(slc.max()-slc.min())\n",
    "\n",
    "    #apply inverse transform on image\n",
    "    with torch.no_grad():\n",
    "        input_img = normalize_inv(input[0])\n",
    "    #plot image and its saleincy map\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.imshow(np.transpose(input_img.cpu().detach().numpy(), (1, 2, 0)))\n",
    "    plt.axis('off')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.imshow(slc.cpu().numpy(), cmap=plt.cm.hot)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32af64a0-f133-4ca8-b789-14cfb5f459ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_batch, label_batch = next(dloader_iter)\n",
    "saliency(img_batch.to(device), model, label_batch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
